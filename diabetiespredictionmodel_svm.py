# -*- coding: utf-8 -*-
"""DiabetiesPredictionModel_SVM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zlqudL9o4Sj2z2OhAZnOz262q_xLyeoT
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

df = pd.read_csv('/content/diabetes.csv')

df.head(10)

df.tail(10)

df.shape

df.dtypes

df.describe()

df.isnull().sum()

df.nunique()

df.duplicated()

df.columns

df.groupby('Outcome').mean()

df['Outcome'].value_counts()

#Data Spliting
from sklearn.model_selection import train_test_split

x = df.drop('Outcome',axis = 1)
y = df['Outcome']

print(x)

print(y)

#Data Standardization
from sklearn.preprocessing import StandardScaler

scalar = StandardScaler()

x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2,random_state = 2025)

print(x_train)

print(x_test)

print(y_train)

x_train.shape

x_test.shape

x_train_scaled = scalar.fit_transform(x_train)
x_test_scaled = scalar.transform(x_test)

#Call all the model
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC

knc = KNeighborsClassifier(n_neighbors = 10)
dtc = DecisionTreeClassifier()
rfc = RandomForestClassifier(n_estimators = 200)
lr = LogisticRegression()
svc = SVC(kernel = 'linear')

#KNC
knc.fit(x_train_scaled, y_train)

#Prediction for knc
y_pred = knc.predict(x_test_scaled)

y_pred

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

print(f'{accuracy_score(y_test,y_pred)}')
print(f'{precision_score(y_test,y_pred)}')
print(f'{recall_score(y_test,y_pred)}')
print(f'{f1_score(y_test,y_pred)}')

#Decision_Tree
dtc.fit(x_train_scaled, y_train)

y_pred = dtc.predict(x_test_scaled)

print(f'{accuracy_score(y_test,y_pred)}')
print(f'{precision_score(y_test,y_pred)}')
print(f'{recall_score(y_test,y_pred)}')
print(f'{f1_score(y_test,y_pred)}')

rfc.fit(x_train_scaled,y_train)

y_pred = rfc.predict(x_test_scaled)

print(f'{accuracy_score(y_test,y_pred)}')
print(f'{precision_score(y_test,y_pred)}')
print(f'{recall_score(y_test,y_pred)}')
print(f'{f1_score(y_test,y_pred)}')

#Logistic Regression
lr.fit(x_train_scaled,y_train)

y_pred = lr.predict(x_test_scaled)

print(f'{accuracy_score(y_test,y_pred)}')
print(f'{precision_score(y_test,y_pred)}')
print(f'{recall_score(y_test,y_pred)}')
print(f'{f1_score(y_test,y_pred)}')

#SVC
svc.fit(x_train_scaled, y_train)

ypred = svc.predict(x_test_scaled)

print(f'{accuracy_score(y_test,y_pred)}')
print(f'{precision_score(y_test,y_pred)}')
print(f'{recall_score(y_test,y_pred)}')
print(f'{f1_score(y_test,y_pred)}')

df.columns

#Make a predictive System

input = (3, 166, 80, 17, 185, 26, 0.6, 47)

#Changing the input to a numpyarray
input_data_numpyarray = np.asarray(input)

#Reshape
input_data_reshaped = input_data_numpyarray.reshape(1,-1)

#Standardization of input data
std_data = scalar.transform(input_data_reshaped)
print(std_data)

#Prediction
prediction = rfc.predict(std_data)
if (prediction[0] == 0):
  print('The person is not Diabetic')
else:
  print('The person is Diabetic')